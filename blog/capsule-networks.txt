Capsule Networks

10 January 2018

In the nervous system, we know that neurons communicate by transmitting short spikes along axons, which are detected and transmitted by adjacent neurons. What is unknown, however, is exactly how information is actually represented in the series of spikes that any neuron propagates. Depending on who you ask, information could be contained in the frequency of activity, in the delay between spikes, in the population activity of a group of neurons, or even in a single spike itself. In neural networks, the silicon counterparts to biological brains, information is encoded in the magnitude of scalar quantities. At each layer of a neural network, the combination of the activations at each neuron and the weights of the next layer, determines the output values of the next layer in the network. Fundamentally, for a given input, all the information becomes encoded in these scalar values. In fact, if we were to reduce the network down to a single neuron in each layer (not a particularly useful network) then at each layer the response of the network to the input feature would be contained in one single scalar value.

In a capsule network, activity is represented by a vector. That is, if we again reduced our network to only a single neuron in each layer (essentially a chain of neurons from input to output), then at each layer we would have a vector representing the output, rather than a scalar. Then, rather than multiplying this output value by the next weight value, we simply take the dot product between this vector and a matrix of weight values.

Intuitively, Hinton noted that one of the limitations of standard neural networks is that they are not particularly discerning. In a convolutional network, we explicitly teach each feature detector (each convolutional unit) to output the same response to an input feature, even if that input feature changes in pose or position (and even slight changes in appearance). In practice, we say that these detectors are robust to changes in pose or appearance. For instance if we are training a network to differentiate between apples and bananas, then we need our feature detectors to recognise that while no apples look like bananas, neither do any two apples look identical.

In the ideal case, for a network that recognises faces in images, feature detectors that identify whether eyes are present will output a particular value if eyes are present, and a different value if they are not. When this is true we say that this detector is invariant. That is, its output does not vary as valid inputs do.

This framework has been shown to work well in practice - however with many known limitations.

Alternatively, by using capsules (vectors) we can extend the scalar representation of activities to a vector representation and move from invariance to equivariance. Imagine we are training a network to detect whether a two-dimensional point lies on a known circle. In a traditional network our training data would be a series of two dimensional points, each labelled with whether they are on a circle or not. Certain neurons in the network would then tend give one response when the points lie on the circle, and different responses when the points lie off it. Crucially, however, this network is invariant to which input point it is currently seeing. This means that we can choose any point on the circle, and the network should always generate the same response. In contrast, because activities in a capsule network are vectors, we can encode not only the presence of a feature, but also its direction (which can actually represent anything). This means that the output of a particular neuron in a circle detection network will change, exactly as the input changes. Specifically, the magnitude of an activation tells us whether a feature is present (is the point on the circle?) while the direction of the activation tells us something about its quality (in this case, where on the circle is the feature).

The rest of the capsule networks paper deal with how to train networks that contain vector activations - essentially by deciding which neurons in layer (k + 1) should receive input from neurons in layer k.

After reading the capsule network papers I have two thoughts. The first: could capsule networks be a future candidate for applications in quantum machine learning? Qubits are (sort of) vectors, perhaps this could be an important conceptual breakthrough in our quantum machine learning journey? (Note that I have only very recently begun learning about quantum computation, so this thought could be wildly inaccurate - I would love to hear from anyone that knows about the topic).

The original artificial neural networks of Rosenblatt used binary activations, then we moved to scalar activations and now more recently have vector activations. Does this mean there is a future for matrix based activations? Rather than representing each activation as a vector, we could instead use a population of vectors, which could perhaps represent a distribution over output values. This could be useful in activity recognition scenarios - where a distribution of output vectors could encode both the current state of an input feature, as well as possible future states. The routing algorithm could be adapted to use information theory measures of similarity between distributions to update the weight vectors.

If anyone is interested in discussing capsule networks or quantum machine learning (which I'm going to discuss more as I keep reading) further, then please feel free to contact me at jordan@jordancampbell.org, or on twitter @jordanNZ_AR.

I'm also available for any tech consulting work.
